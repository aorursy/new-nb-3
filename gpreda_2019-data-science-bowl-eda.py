import numpy as np

import pandas as pd

import os

import json

import matplotlib

import seaborn as sns

import matplotlib.pyplot as plt

from tqdm import tqdm_notebook

def read_data():

    print(f'Read data')

    train_df = pd.read_csv('../input/data-science-bowl-2019/train.csv')

    test_df = pd.read_csv('../input/data-science-bowl-2019/test.csv')

    train_labels_df = pd.read_csv('../input/data-science-bowl-2019/train_labels.csv')

    specs_df = pd.read_csv('../input/data-science-bowl-2019/specs.csv')

    sample_submission_df = pd.read_csv('../input/data-science-bowl-2019/sample_submission.csv')

    print(f"train shape: {train_df.shape}")

    print(f"test shape: {test_df.shape}")

    print(f"train labels shape: {train_labels_df.shape}")

    print(f"specs shape: {specs_df.shape}")

    print(f"sample submission shape: {sample_submission_df.shape}")

    return train_df, test_df, train_labels_df, specs_df, sample_submission_df
train_df, test_df, train_labels_df, specs_df, sample_submission_df = read_data()
train_df.head()
test_df.head()
train_labels_df.head()
pd.set_option('max_colwidth', 150)

specs_df.head()
sample_submission_df.head()
print(f"train installation id: {train_df.installation_id.nunique()}")

print(f"test installation id: {test_df.installation_id.nunique()}")

print(f"test & submission installation ids identical: {set(test_df.installation_id.unique()) == set(sample_submission_df.installation_id.unique())}")
def missing_data(data):

    total = data.isnull().sum()

    percent = (data.isnull().sum()/data.isnull().count()*100)

    tt = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])

    types = []

    for col in data.columns:

        dtype = str(data[col].dtype)

        types.append(dtype)

    tt['Types'] = types

    return(np.transpose(tt))
missing_data(train_df)
missing_data(test_df)
missing_data(train_labels_df)
missing_data(specs_df)
def unique_values(data):

    total = data.count()

    tt = pd.DataFrame(total)

    tt.columns = ['Total']

    uniques = []

    for col in data.columns:

        unique = data[col].nunique()

        uniques.append(unique)

    tt['Uniques'] = uniques

    return(np.transpose(tt))
unique_values(train_df)
unique_values(test_df)
unique_values(train_labels_df)
unique_values(specs_df)
def most_frequent_values(data):

    total = data.count()

    tt = pd.DataFrame(total)

    tt.columns = ['Total']

    items = []

    vals = []

    for col in data.columns:

        itm = data[col].value_counts().index[0]

        val = data[col].value_counts().values[0]

        items.append(itm)

        vals.append(val)

    tt['Most frequent item'] = items

    tt['Frequence'] = vals

    tt['Percent from total'] = np.round(vals / total * 100, 3)

    return(np.transpose(tt))
most_frequent_values(train_df)
most_frequent_values(test_df)
most_frequent_values(train_labels_df)
most_frequent_values(specs_df)
def plot_count(feature, title, df, size=1):

    f, ax = plt.subplots(1,1, figsize=(4*size,4))

    total = float(len(df))

    g = sns.countplot(df[feature], order = df[feature].value_counts().index[:20], palette='Set3')

    g.set_title("Number and percentage of {}".format(title))

    if(size > 2):

        plt.xticks(rotation=90, size=8)

    for p in ax.patches:

        height = p.get_height()

        ax.text(p.get_x()+p.get_width()/2.,

                height + 3,

                '{:1.2f}%'.format(100*height/total),

                ha="center") 

    plt.show()    
plot_count('title', 'title (first most frequent 20 values - train)', train_df, size=4)
plot_count('title', 'title (first most frequent 20 values - test)', test_df, size=4)
print(f"Title values (train): {train_df.title.nunique()}")

print(f"Title values (test): {test_df.title.nunique()}")
plot_count('type', 'type - train', train_df, size=2)
plot_count('type', 'type - test', test_df, size=2)
plot_count('world', 'world - train', train_df, size=2)
plot_count('world', 'world - test', test_df, size=2)
plot_count('event_code', 'event_code - test', train_df, size=4)
plot_count('event_code', 'event_code - test', test_df, size=4)
for column in train_labels_df.columns.values:

    print(f"[train_labels] Unique values of {column} : {train_labels_df[column].nunique()}")
plot_count('title', 'title - train_labels', train_labels_df, size=3)
plot_count('accuracy', 'accuracy - train_labels', train_labels_df, size=4)
plot_count('accuracy_group', 'accuracy_group - train_labels', train_labels_df, size=2)
plot_count('num_correct', 'num_correct - train_labels', train_labels_df, size=2)
plot_count('num_incorrect', 'num_incorrect - train_labels', train_labels_df, size=4)
for column in specs_df.columns.values:

    print(f"[specs] Unique values of `{column}`: {specs_df[column].nunique()}")
sample_train_df = train_df.sample(100000)
sample_train_df.head()
sample_train_df.iloc[0].event_data
sample_train_df.iloc[1].event_data

extracted_event_data = pd.io.json.json_normalize(sample_train_df.event_data.apply(json.loads))
print(f"Extracted data shape: {extracted_event_data.shape}")
extracted_event_data.head(10)
missing_data(extracted_event_data)
def existing_data(data):

    total = data.isnull().count() - data.isnull().sum()

    percent = 100 - (data.isnull().sum()/data.isnull().count()*100)

    tt = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])

    tt = pd.DataFrame(tt.reset_index())

    return(tt.sort_values(['Total'], ascending=False))
stat_event_data = existing_data(extracted_event_data)
plt.figure(figsize=(10, 10))

sns.set(style='whitegrid')

ax = sns.barplot(x='Percent', y='index', data=stat_event_data.head(40), color='blue')

plt.title('Most frequent features in event data')

plt.ylabel('Features')
stat_event_data[['index', 'Percent']].head(20)
specs_df.args[0]
specs_args_extracted = pd.DataFrame()

for i in range(0, specs_df.shape[0]): 

    for arg_item in json.loads(specs_df.args[i]) :

        new_df = pd.DataFrame({'event_id': specs_df['event_id'][i],\

                               'info':specs_df['info'][i],\

                               'args_name': arg_item['name'],\

                               'args_type': arg_item['type'],\

                               'args_info': arg_item['info']}, index=[i])

        specs_args_extracted = specs_args_extracted.append(new_df)
print(f"Extracted args from specs: {specs_args_extracted.shape}")
specs_args_extracted.head(5)
tmp = specs_args_extracted.groupby(['event_id'])['info'].count()

df = pd.DataFrame({'event_id':tmp.index, 'count': tmp.values})

plt.figure(figsize=(6,4))

sns.set(style='whitegrid')

ax = sns.distplot(df['count'],kde=True,hist=False, bins=40)

plt.title('Distribution of number of arguments per event_id')

plt.xlabel('Number of arguments'); plt.ylabel('Density'); plt.show()
plot_count('args_name', 'args_name (first 20 most frequent values) - specs', specs_args_extracted, size=4)
plot_count('args_type', 'args_type - specs', specs_args_extracted, size=3)
plot_count('args_info', 'args_info (first 20 most frequent values) - specs', specs_args_extracted, size=4)
def extract_time_features(df):

    df['timestamp'] = pd.to_datetime(df['timestamp'])

    df['date'] = df['timestamp'].dt.date

    df['month'] = df['timestamp'].dt.month

    df['hour'] = df['timestamp'].dt.hour

    df['year'] = df['timestamp'].dt.year

    df['dayofweek'] = df['timestamp'].dt.dayofweek

    df['weekofyear'] = df['timestamp'].dt.weekofyear

    df['dayofyear'] = df['timestamp'].dt.dayofyear

    df['quarter'] = df['timestamp'].dt.quarter

    df['is_month_start'] = df['timestamp'].dt.is_month_start

    return df
train_df = extract_time_features(train_df)
test_df = extract_time_features(test_df)
train_df.head()
test_df.head()
plot_count('year', 'year - train', train_df, size=1)
plot_count('month', 'month - train', train_df, size=1)
plot_count('hour', 'hour -  train', train_df, size=4)
plot_count('dayofweek', 'dayofweek - train', train_df, size=2)
plot_count('weekofyear', 'weekofyear - train', train_df, size=2)
plot_count('is_month_start', 'is_month_start - train', train_df, size=1)
plot_count('year', 'year - test', test_df, size=1)
plot_count('month', 'month - test', test_df, size=1)
plot_count('hour', 'hour -  test', test_df, size=4)
plot_count('dayofweek', 'dayofweek - test', test_df, size=2)
plot_count('weekofyear', 'weekofyear - test', test_df, size=2)
plot_count('is_month_start', 'is_month_start - test', test_df, size=1)
numerical_columns = ['game_time', 'month', 'dayofweek', 'hour']

categorical_columns = ['type', 'world']



comp_train_df = pd.DataFrame({'installation_id': train_df['installation_id'].unique()})

comp_train_df.set_index('installation_id', inplace = True)
def get_numeric_columns(df, column):

    df = df.groupby('installation_id').agg({f'{column}': ['mean', 'sum', 'min', 'max', 'std', 'skew']})

    df[column].fillna(df[column].mean(), inplace = True)

    df.columns = [f'{column}_mean', f'{column}_sum', f'{column}_min', f'{column}_max', f'{column}_std', f'{column}_skew']

    return df
for i in numerical_columns:

    comp_train_df = comp_train_df.merge(get_numeric_columns(train_df, i), left_index = True, right_index = True)
print(f"comp_train shape: {comp_train_df.shape}")
comp_train_df.head()
# get the mode of the title

labels_map = dict(train_labels_df.groupby('title')['accuracy_group'].agg(lambda x:x.value_counts().index[0]))

# merge target

labels = train_labels_df[['installation_id', 'title', 'accuracy_group']]

# replace title with the mode

labels['title'] = labels['title'].map(labels_map)

# join train with labels

comp_train_df = labels.merge(comp_train_df, on = 'installation_id', how = 'left')

print('We have {} training rows'.format(comp_train_df.shape[0]))
comp_train_df.head()
print(f"comp_train_df shape: {comp_train_df.shape}")

for feature in comp_train_df.columns.values[3:20]:

    print(f"{feature} unique values: {comp_train_df[feature].nunique()}")
plot_count('title', 'title - compound train', comp_train_df)
plot_count('accuracy_group', 'accuracy_group - compound train', comp_train_df, size=2)
plt.figure(figsize=(16,6))

_titles = comp_train_df.title.unique()

plt.title("Distribution of log(`game time mean`) values (grouped by title) in the comp train")

for _title in _titles:

    red_comp_train_df = comp_train_df.loc[comp_train_df.title == _title]

    sns.distplot(np.log(red_comp_train_df['game_time_mean']), kde=True, label=f'title: {_title}')

plt.legend()

plt.show()
plt.figure(figsize=(16,6))

_titles = comp_train_df.title.unique()

plt.title("Distribution of log(`game time std`) values (grouped by title) in the comp train")

for _title in _titles:

    red_comp_train_df = comp_train_df.loc[comp_train_df.title == _title]

    sns.distplot(np.log(red_comp_train_df['game_time_std']), kde=True, label=f'title: {_title}')

plt.legend()

plt.show()
plt.figure(figsize=(16,6))

_titles = comp_train_df.title.unique()

plt.title("Distribution of `game time skew` values (grouped by title) in the comp train")

for _title in _titles:

    red_comp_train_df = comp_train_df.loc[comp_train_df.title == _title]

    sns.distplot(red_comp_train_df['game_time_skew'], kde=True, label=f'title: {_title}')

plt.legend()

plt.show()
plt.figure(figsize=(16,6))

_titles = comp_train_df.title.unique()

plt.title("Distribution of `hour mean` values (grouped by title) in the comp train")

for _title in _titles:

    red_comp_train_df = comp_train_df.loc[comp_train_df.title == _title]

    sns.distplot(red_comp_train_df['hour_mean'], kde=True, label=f'title: {_title}')

plt.legend()

plt.show()
plt.figure(figsize=(16,6))

_titles = comp_train_df.title.unique()

plt.title("Distribution of `hour std` values (grouped by title) in the comp train")

for _title in _titles:

    red_comp_train_df = comp_train_df.loc[comp_train_df.title == _title]

    sns.distplot(red_comp_train_df['hour_std'], kde=True, label=f'title: {_title}')

plt.legend()

plt.show()
plt.figure(figsize=(16,6))

_titles = comp_train_df.title.unique()

plt.title("Distribution of `hour skew` values (grouped by title) in the comp train")

for _title in _titles:

    red_comp_train_df = comp_train_df.loc[comp_train_df.title == _title]

    sns.distplot(red_comp_train_df['hour_skew'], kde=True, label=f'title: {_title}')

plt.legend()

plt.show()
plt.figure(figsize=(16,6))

_titles = comp_train_df.title.unique()

plt.title("Distribution of `month mean` values (grouped by title) in the comp train")

for _title in _titles:

    red_comp_train_df = comp_train_df.loc[comp_train_df.title == _title]

    sns.distplot(red_comp_train_df['month_mean'], kde=True, label=f'title: {_title}')

plt.legend()

plt.show()
plt.figure(figsize=(16,6))

_titles = comp_train_df.title.unique()

plt.title("Distribution of `month std` values (grouped by title) in the comp train")

for _title in _titles:

    red_comp_train_df = comp_train_df.loc[comp_train_df.title == _title]

    sns.distplot(red_comp_train_df['month_std'], kde=True, label=f'title: {_title}')

plt.legend()

plt.show()
plt.figure(figsize=(16,6))

_titles = comp_train_df.title.unique()

plt.title("Distribution of `month skew` values (grouped by title) in the comp train")

for _title in _titles:

    red_comp_train_df = comp_train_df.loc[comp_train_df.title == _title]

    sns.distplot(red_comp_train_df['month_skew'], kde=True, label=f'title: {_title}')

plt.legend()

plt.show()
plt.figure(figsize=(16,6))

_accuracy_groups = comp_train_df.accuracy_group.unique()

plt.title("Distribution of log(`game time mean`) values (grouped by accuracy group) in the comp train")

for _accuracy_group in _accuracy_groups:

    red_comp_train_df = comp_train_df.loc[comp_train_df.accuracy_group == _accuracy_group]

    sns.distplot(np.log(red_comp_train_df['game_time_mean']), kde=True, label=f'accuracy group= {_accuracy_group}')

plt.legend()

plt.show()
plt.figure(figsize=(16,6))

_accuracy_groups = comp_train_df.accuracy_group.unique()

plt.title("Distribution of log(`game time std`) values (grouped by accuracy group) in the comp train")

for _accuracy_group in _accuracy_groups:

    red_comp_train_df = comp_train_df.loc[comp_train_df.accuracy_group == _accuracy_group]

    sns.distplot(np.log(red_comp_train_df['game_time_std']), kde=True, label=f'accuracy group= {_accuracy_group}')

plt.legend()

plt.show()
plt.figure(figsize=(16,6))

_accuracy_groups = comp_train_df.accuracy_group.unique()

plt.title("Distribution of `game time skew` values (grouped by accuracy group) in the comp train")

for _accuracy_group in _accuracy_groups:

    red_comp_train_df = comp_train_df.loc[comp_train_df.accuracy_group == _accuracy_group]

    sns.distplot(red_comp_train_df['game_time_skew'], kde=True, label=f'accuracy group= {_accuracy_group}')

plt.legend()

plt.show()
plt.figure(figsize=(16,6))

_accuracy_groups = comp_train_df.accuracy_group.unique()

plt.title("Distribution of `hour mean` values (grouped by accuracy group) in the comp train")

for _accuracy_group in _accuracy_groups:

    red_comp_train_df = comp_train_df.loc[comp_train_df.accuracy_group == _accuracy_group]

    sns.distplot(red_comp_train_df['hour_mean'], kde=True, label=f'accuracy group= {_accuracy_group}')

plt.legend()

plt.show()
plt.figure(figsize=(16,6))

_accuracy_groups = comp_train_df.accuracy_group.unique()

plt.title("Distribution of `hour std` values (grouped by accuracy group) in the comp train")

for _accuracy_group in _accuracy_groups:

    red_comp_train_df = comp_train_df.loc[comp_train_df.accuracy_group == _accuracy_group]

    sns.distplot(red_comp_train_df['hour_std'], kde=True, label=f'accuracy group= {_accuracy_group}')

plt.legend()

plt.show()
plt.figure(figsize=(16,6))

_accuracy_groups = comp_train_df.accuracy_group.unique()

plt.title("Distribution of `hour skew` values (grouped by accuracy group) in the comp train")

for _accuracy_group in _accuracy_groups:

    red_comp_train_df = comp_train_df.loc[comp_train_df.accuracy_group == _accuracy_group]

    sns.distplot(red_comp_train_df['hour_skew'], kde=True, label=f'accuracy group= {_accuracy_group}')

plt.legend()

plt.show()
plt.figure(figsize=(16,6))

_accuracy_groups = comp_train_df.accuracy_group.unique()

plt.title("Distribution of `month mean` values (grouped by accuracy group) in the comp train")

for _accuracy_group in _accuracy_groups:

    red_comp_train_df = comp_train_df.loc[comp_train_df.accuracy_group == _accuracy_group]

    sns.distplot(red_comp_train_df['month_mean'], kde=True, label=f'accuracy group= {_accuracy_group}')

plt.legend()

plt.show()
plt.figure(figsize=(16,6))

_accuracy_groups = comp_train_df.accuracy_group.unique()

plt.title("Distribution of `month std` values (grouped by accuracy group) in the comp train")

for _accuracy_group in _accuracy_groups:

    red_comp_train_df = comp_train_df.loc[comp_train_df.accuracy_group == _accuracy_group]

    sns.distplot(red_comp_train_df['month_std'], kde=True, label=f'accuracy group= {_accuracy_group}')

plt.legend()

plt.show()
plt.figure(figsize=(16,6))

_accuracy_groups = comp_train_df.accuracy_group.unique()

plt.title("Distribution of `month skew` values (grouped by accuracy group) in the comp train")

for _accuracy_group in _accuracy_groups:

    red_comp_train_df = comp_train_df.loc[comp_train_df.accuracy_group == _accuracy_group]

    sns.distplot(red_comp_train_df['month_skew'], kde=True, label=f'accuracy group= {_accuracy_group}')

plt.legend()

plt.show()